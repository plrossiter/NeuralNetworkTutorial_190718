{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perceptron using class structure\n",
    "#'n_inputs' inputs, \n",
    "#'n_inputs' synapses, \n",
    "#1 neuron, \n",
    "#1 layer\n",
    "#1 output\n",
    "# All neurons use linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, n_inputs):\n",
    "        #initialize synaptic weights\n",
    "        np.random.seed()\n",
    "        self.synaptic_weights = 2* np.random.random((n_inputs,1)) -1\n",
    "        self.final_outputs =[]\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1/ (1+ np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return np.exp(-x) / pow(1+np.exp(-x),2)\n",
    "        \n",
    "    def train(self, training_inputs, training_outputs, training_iterations):\n",
    "        for i in range(training_iterations):  \n",
    "            outputs = self.think(training_inputs)\n",
    "            error = training_outputs - outputs\n",
    "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(outputs))\n",
    "            \n",
    "            cost = self.cost_function(training_outputs, outputs)\n",
    "            cost_grads = self.cost_gradient_function(training_outputs, outputs, training_inputs)\n",
    "            print \"cost_grads.T: \"\n",
    "            print cost_grads.T\n",
    "            print \"adjustments: \"\n",
    "            print adjustments\n",
    "            print \"cost_grads * error: \"\n",
    "            print cost_grads.shape\n",
    "            print \"\\n\"\n",
    "            \n",
    "            self.synaptic_weights +=adjustments\n",
    "        self.final_outputs = outputs\n",
    "        return 0\n",
    "\n",
    "    def think(self, inputs):\n",
    "        #LIN.REG.: outputs = sum(x_0*w_0 + x_1*w_1 +...+ x_n*w_n) where n = n_inputs\n",
    "        inputs = inputs.astype(float)\n",
    "        outputs = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
    "        return outputs\n",
    "    \n",
    "    def cost_function(self, training_outputs, hypothesised_outputs):\n",
    "        #SUM OF SQUARES\n",
    "        return np.sum(pow(training_outputs - hypothesised_outputs ,2))\n",
    "\n",
    "    def cost_gradient_function(self, training_outputs, hypothesised_outputs, training_inputs):\n",
    "        cost_grad = -1*(training_outputs - hypothesised_outputs)*training_inputs\n",
    "        cost_grads = []\n",
    "        for i in cost_grad.T:\n",
    "            cost_grads.append(np.sum(i))\n",
    "        return np.asarray(cost_grads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial random synaptic_weights: \n",
      "[[-0.02693742]\n",
      " [-0.53681492]\n",
      " [ 0.01173835]]\n",
      "\n",
      "----------\n",
      "\n",
      "cost_grads.T: \n",
      "[-1.13840242 -0.2629368  -0.26380194]\n",
      "adjustments: \n",
      "[[0.27197539]\n",
      " [0.06369059]\n",
      " [0.06408889]]\n",
      "cost_grads * error: \n",
      "(3,)\n",
      "\n",
      "\n",
      "cost_grads.T: \n",
      "[-0.95845632 -0.1360295  -0.03754667]\n",
      "adjustments: \n",
      "[[0.22433012]\n",
      " [0.03103028]\n",
      " [0.00641215]]\n",
      "cost_grads * error: \n",
      "(3,)\n",
      "\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "\n",
      "Synaptic weights after training: \n",
      "[[ 0.46936809]\n",
      " [-0.44209405]\n",
      " [ 0.08223939]]\n",
      "\n",
      "Outputs after training: \n",
      "[[0.51894773]\n",
      " [0.46200859]\n",
      " [0.5795351 ]\n",
      " [0.40196192]]\n"
     ]
    }
   ],
   "source": [
    "#Example 1 - 3 input variables\n",
    "\n",
    "#Define training inputs and outputs\n",
    "training_inputs = np.array([[0,0,1],\n",
    "                           [1,1,1],\n",
    "                           [1,0,1],\n",
    "                           [0,1,1]])\n",
    "\n",
    "training_outputs = np.array([[0,1,1,0]]).T\n",
    "\n",
    "n_inputs=len(training_inputs[0])\n",
    "\n",
    "neural_network = NeuralNetwork(n_inputs)\n",
    "\n",
    "\n",
    "print \"Initial random synaptic_weights: \"\n",
    "print(neural_network.synaptic_weights)\n",
    "\n",
    "print \"\\n----------\\n\"\n",
    "neural_network.train(training_inputs, training_outputs, 2)\n",
    "\n",
    "print \"\\n----------\\n\"\n",
    "print \"\\nSynaptic weights after training: \"\n",
    "print neural_network.synaptic_weights\n",
    "\n",
    "print \"\\nOutputs after training: \"\n",
    "print neural_network.final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial random synaptic_weights: \n",
      "[[ 0.65537092]\n",
      " [-0.43519054]\n",
      " [-0.5528945 ]\n",
      " [-0.41253608]]\n",
      "\n",
      "Synaptic weights after training: \n",
      "[[-8.43818084]\n",
      " [17.85545618]\n",
      " [-0.4066965 ]\n",
      " [-0.40669069]]\n",
      "\n",
      "Outputs after training: \n",
      "[[1.44105396e-04]\n",
      " [9.99816633e-01]\n",
      " [9.99877898e-01]\n",
      " [9.59566523e-05]\n",
      " [2.16407536e-04]\n",
      " [9.99918695e-01]\n",
      " [1.44104559e-04]\n",
      " [9.99877898e-01]]\n",
      "\n",
      "\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Example 2 - 4 input variables, larger dataset (m=8)\n",
    "\n",
    "#Define training inputs and outputs\n",
    "training_inputs = np.array([[1,0,0,1],\n",
    "                           [1,1,1,1],\n",
    "                           [1,1,0,1],\n",
    "                           [1,0,1,1],\n",
    "                           [1,0,0,0],\n",
    "                           [1,1,0,0],\n",
    "                           [1,0,1,0],\n",
    "                           [1,1,1,0]])\n",
    "\n",
    "training_outputs = np.array([[0,1,1,0,0,1,0,1]]).T\n",
    "\n",
    "n_inputs=len(training_inputs[0])\n",
    "neural_network = NeuralNetwork(n_inputs)\n",
    "\n",
    "print \"Initial random synaptic_weights: \"\n",
    "print(neural_network.synaptic_weights)\n",
    "\n",
    "\n",
    "neural_network.train(training_inputs, training_outputs, 20000)\n",
    "\n",
    "print \"\\nSynaptic weights after training: \"\n",
    "print neural_network.synaptic_weights\n",
    "\n",
    "print \"\\nOutputs after training: \"\n",
    "print neural_network.final_outputs\n",
    "\n",
    "print \"\\n\"\n",
    "for i in neural_network.final_outputs:\n",
    "    if float(i[0]) > .99:\n",
    "        i[0] == 1.\n",
    "        print \"1\"\n",
    "    elif float(i[0]) < 0.01:\n",
    "        i[0] == 0.\n",
    "        print \"0\"\n",
    "    else:\n",
    "        print i[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyROOT - Python3 [conda env:root]",
   "language": "python",
   "name": "conda-root-pyroot3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
